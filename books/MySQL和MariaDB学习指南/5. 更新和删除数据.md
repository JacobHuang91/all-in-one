# 更新数据

```sql
UPDATE birdwatchers.humans
SET country_id = 'us';

UPDATE humans
SET name_last = 'Johnson'
WHERE human_id = 3;

UPDATE humans
SET formal_title = 'Ms.'
WHERE human_id IN(24, 32);



ALTER TABLE humans
CHANGE COLUMN formal_title formal_title ENUM('Mr.','Ms.');


-- 随机抽取中奖者并更新table
-- RAND()函数,给符合WHERE条件的每一行分配一个随机的浮点数
-- 然后，因为我们把它加入ORDER BY了
-- 所以结果集就按照这个随机数来排序了
-- 注1: ORDER BY中使用RAND()可能有性能问题
-- 注2: 在同时更新多个表的时候,不能使用ORDER BY 或者 LIMIT
UPDATE prize_winners
SET winner_date = CURDATE()
WHERE winner_date IS NULL
ORDER BY RAND()
LIMIT 2;

-- 同时更新多个表
UPDATE prize_winners, humans
SET winner_date = NULL,
prize_chosen = NULL,
prize_sent = NULL
WHERE country_id = 'uk'
AND prize_winners.human_id = humans.human_id;

-- 因为在同时更新多个表时候不能使用ORDER BY或LIMIT
-- 所以想办法使用一个表
UPDATE prize_winners
SET winner_date = CURDATE()
WHERE winner_date IS NULL
AND human_id IN
(SELECT human_id
FROM humans
WHERE country_id = 'uk'
ORDER BY RAND())
LIMIT 2;
```

# 处理重复

INSERT...ON DUPLICATE KEY UPDATE

例子: 从 better_birders_site 导入数据

但是有些数据在当前数据库中存在

```sql
-- 添加一列用来区分是不是新导入的数据
-- 默认值为 0
-- 对于来自 Better Birders 的记录，其值会被设为 1
-- 而如果是既在 Better Birders，又在我们这边，则记为 2
ALTER TABLE humans
ADD COLUMN better_birders_site TINYINT DEFAULT 0;

-- email为UNIQUE
-- 因为加上了ON DUPLICATE KEY，所以如果发现有重复的电子邮件地址
-- better_birders_site 就会被更新为 2
-- 而没有发现重复的那些行，就会记为 1
INSERT INTO humans
(formal_title, name_first, name_last, email_address, better_birders_site)
VALUES('Mr','Barry','Pilson', 'barry@gomail.com', 1),
('Ms','Lexi','Hollar', 'alexandra@mysqlresources.com', 1),
('Mr','Ricky','Adams', 'ricky@gomail.com', 1)
ON DUPLICATE KEY
UPDATE better_birders_site = 2;
```

# 删除数据

MySQL 没有 UNDELETE 或 UNDO 命令供你恢复被删数据

```sql
DELETE FROM humans
WHERE name_first = 'Elena'
AND name_last = 'Bokova'
AND email_address LIKE '%yahoo.com';

-- 同时删除多个表的数据
DELETE FROM humans, prize_winners
USING humans JOIN prize_winners
WHERE name_first = 'Elena'
AND name_last = 'Bokova'
AND email_address LIKE '%yahoo.com'
AND humans.human_id = prize_winners.human_id;
```
